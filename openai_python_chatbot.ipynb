{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "First, we import the necessary libraries. The openai library is used to interact with the OpenAI API. We also use dotenv to securely load the environment variables, which include the API access credentials.\n",
    "\n",
    "Primeiro, importamos as bibliotecas necessárias. A biblioteca `openai` é usada para interagir com a API da OpenAI. Utilizamos também `dotenv` para carregar as variáveis de ambiente de forma segura, o que inclui as credenciais de acesso à API."
   ],
   "id": "b66640816d6a09eb"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# Set up OpenAI client\n",
    "client = openai.Client()\n"
   ],
   "id": "b069a230491ea9c4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Here, we define the list that will store the messages from the session and the GPT model that will be used. Additionally, we define the text_generate function, which receives the messages and configuration parameters, makes the call to the API, and processes the response, displaying the generated text and the token consumption.\n",
    "\n",
    "Aqui definimos a lista que armazenará as mensagens da sessão e o modelo da GPT que será utilizado. Além disso, definimos a função `text_generate`, que recebe as mensagens e parâmetros de configuração, realiza a chamada à API e processa a resposta, exibindo o texto gerado e o consumo de tokens.\n"
   ],
   "id": "98d31312639b42dd"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "messages_list = []\n",
    "model = 'gpt-3.5-turbo-0125'\n",
    "\n",
    "def text_generate(messages, gpt_model, max_tokens=1000, temperature=0):\n",
    "    response = client.chat.completions.create(\n",
    "        messages=messages,\n",
    "        model=gpt_model,\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=temperature\n",
    "    )\n",
    "    messages_list.append(response.choices[0].message.model_dump(exclude_none=True))\n",
    "    print(f'ChatGPT: {messages[-1][\"content\"]}')\n",
    "    print(f'Tokens: {response.usage.total_tokens}')\n"
   ],
   "id": "eaf7e644be305fcc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "In this cell, we implement a loop to allow the user to continuously interact with the AI model. The loop continues until the user types 'thanks' to exit. If the user types 'info', the message history will be displayed. For any other input, the message is sent to the GPT model for response generation.\n",
    "\n",
    "Nesta célula, implementamos um loop para permitir que o usuário interaja continuamente com o modelo de IA. O loop continua até que o usuário digite 'thanks' para sair. Se o usuário digitar 'info', o histórico das mensagens será exibido. Para qualquer outro input, a mensagem é enviada para o modelo GPT para geração de resposta.\n"
   ],
   "id": "a7acf5661df311ef"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "text = input('Make a question: ')\n",
    "\n",
    "while text.lower() != 'exit':\n",
    "    if text.lower() == 'info':\n",
    "        print(messages_list)\n",
    "        text = input('New question: ')\n",
    "    else:\n",
    "        messages_list.append({'role': 'user', 'content': f'{text}'})\n",
    "        text_generate(messages_list, model, 1000, 0.8)\n",
    "        text = input('New question: ')\n"
   ],
   "id": "505f25e4a757cf9d",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
